import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns



ruta = r'C:\Users\usuari\Desktop\3r dades\APRENENTATGE COMPUTACIONAL\ratings_Electronics.csv'
data = pd.read_csv(ruta, header=None, names=['User ID', 'Product ID', 'Rating', 'Time Stamp'])

data = data.dropna()  # Elimina les files amb valors nuls
data = data[(data['Rating'] >= 1) & (data['Rating'] <= 5)]  # Filtra les classificacions invàlides

# print("Total de columnes després del primer filtratge: ",data.shape[0])

mitjana_compres = data.groupby('User ID').size().mean()
# print(f"La mitjana de compres per usuari és: {mitjana_compres}") 

# Tallem el dataset a 30000 linies per poder filtar aquells usuaris que mínim han fet dues recomanacions
data_retallat = data.head(10000)
data = data_retallat.groupby('User ID').filter(lambda x: len(x) > 1)
# print("Un cop aplicats tots els filtratges tenim una Dataset de: ",data.shape[0],"files.")


# Dividim les dades en un conjunt de train (60%) i un altre de temporal (40%)
train, temp = train_test_split(data, test_size=0.4, random_state=42)
# Dividim el conjunt temporal en un de test(50%) i un de validació (50%)
test, validation = train_test_split(temp, test_size=0.5, random_state=42)

"""
print("\nConjunt de train")
print(train)

print("\nConjunt de test:")
print(test)

print("\nConjunt de validació:")
print(validation)
"""

# Guardarem els datasets filtrats en CSV
train.to_csv('train_dataset.csv', index=False)
test.to_csv('test_dataset.csv', index=False)
validation.to_csv('validation_dataset.csv', index=False)



recomanador = print("Quin tipus de recomanador vols fer servir? : ")


if recomanador == "user" : 
    usuari_a_recommanar = user_item_matriu.index[0] 
    recomanacions = recomanador_productes(usuari_a_recommanar, numero_recomanacions=5)

    print(f"Recomanacions per a l'usuari {usuari_a_recommanar}:")
    print(recomanacions)



